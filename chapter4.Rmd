---
output: html_document
editor_options: 
  chunk_output_type: console
---
# *3. Clustering and classification - week 4*
```{r}
date()
```


The data set this week is about: Housing values in suburbs of Boston (source:https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html)
there are several variables that affect the housing values such as: criminality, infrastructure, density, size of the house...   
 

#  _Data Analysis_     
crim:     per capita crime rate by town.  
zn:    proportion of residential land zoned for lots over 25,000 sq.ft.  
indus:    proportion of non-retail business acres per town.  
chas:    Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).   
nox:    nitrogen oxides concentration (parts per 10 million).   
rm:    average number of rooms per dwelling.  
age:    proportion of owner-occupied units built prior to 1940.  
dis:    weighted mean of distances to five Boston employment centres.  
rad:    index of accessibility to radial highways.  
tax:    full-value property-tax rate per \$10,000.   
ptratio:    pupil-teacher ratio by town.   
black:    1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.   
lstat:    lower status of the population (percent).   
medv:    median value of owner-occupied homes in \$1000s.   

```{r}
library(MASS)
library(corrplot)
library(ggplot2)
library(GGally)
library (plotly)
data("Boston")
dim(Boston)
str(Boston)

```


```{r}
cor<-cor(Boston, method = "pearson", use = "complete.obs")
round(cor, 2)
corrplot.mixed(cor, lower = "ellipse", upper="number",   tl.col = "black", tl.srt = 45)
```

Bigger houses are more expensive (number of rooms r=0.7), the house value is lower for lower status people (r=0.74). There are intercorrelation between the variables that can explain the houses values.

## Scaling the data. 
Here we subtract the column means from the corresponding columns and divide the difference with standard deviation, all the variables have a mean=0.


```{r}
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
```

creating a quantile vector of crime
```{r}
bins <- quantile(boston_scaled$crim)
bins
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
```


Dividing the dataset to train and test sets, so that 80% of the data belongs to the train set.

```{r}
ncol <- nrow(boston_scaled)
ind <- sample(ncol,  size = ncol * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
```

Fitting the linear discriminant analysis (LDA) and LDA (bi)plot.

LDA is a classification (and dimension reduction) method. It finds the (linear) combination of the variables that separate the target variable classes. The target can be binary or multiclass variable.

```{r}
lda.fit <- lda(crime ~ ., data = train)

lda.arrows <- function(x, myscale = 3, arrow_heads = 0.1, color = "orange", tex = 1.25, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)}# the function for lda biplot arrows (datacamp)
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 3)

```

The plot shows that there are more crimes in areas with close access to the highway and in the residential zones, as showed in the correlation matrix.

```{r}
correct_classes<-test$crime
test <- dplyr::select(test, -crime)
lda.pred <- predict(lda.fit, newdata = test) #Test=the rest=20% 
table(correct = correct_classes, predicted = lda.pred$class)
```

Similar to the LDA, more crimes are expected in high and low class neighbourhoods.

## K-means and clustering data. 

The optimal number of clusters is -> 2
```{r}
data("Boston")
boston_scaled <- as.data.frame(scale(Boston))
dis<-dist(boston_scaled)
summary(dis)

set.seed(123)
k_max <- 20
twcss <- sapply(1:k_max, function(k){kmeans(Boston, k)$tot.withinss})# calculate the total within sum of squares
qplot(x = 1:k_max, y = twcss, geom = 'line')
```

Visualization of the clusters per variable:
```{r, out.width="150%"}
km <-kmeans(boston_scaled, centers = 2)
ggpairs(boston_scaled, mapping = aes(colour=as.factor(km$cluster)), legend = 1,
        upper = list(continuous =wrap("cor", size=3)),
        title="clusters overview",
        lower = list(combo = wrap("facethist",size=0.1, bins = 20, alpha=0.3)))+
  theme(legend.position="bottom")
```


## K-means and clustering data - BONUS.
```{r}
km2 <-kmeans(boston_scaled, centers= 3)
boston_scaled$km_cluster<-km2$cluster

lda.fit2 <- lda(km_cluster ~ ., data = boston_scaled)# linear discriminant analysis
lda.fit2
```

lda biplot
```{r}
classes <- as.numeric(boston_scaled$km_cluster)# target classes as numeric
plot(lda.fit2, dimen = 2, col = classes, pch = classes)# plot the lda results
lda.arrows(lda.fit, myscale = 3)
```
There differences between the clusters, cluster 3 is better explain by rad and tax variables, while cluster one by age.


## ON SALE-> SUPER BONUS.

creating K-means for the training data color by crime insidence

```{r}

model_predictors <- dplyr::select(train, -crime)
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling # matrix multiplication
matrix_product <- as.data.frame(matrix_product)# matrix multiplication
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, 
        color=train$crime, type= 'scatter3d', mode='markers') 
```

Creation of 2 clusters:

```{r}
data("Boston")
boston_scaled <- as.data.frame(scale(Boston))
train <- boston_scaled[ind,]
str(train)
str(Boston)
km3 <-kmeans(train, centers= 2)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, 
        color=as.factor(km3$cluster), type= 'scatter3d', mode='markers')
```

Creation of 3 clusters:

```{r}
data("Boston")
boston_scaled <- as.data.frame(scale(Boston))
train <- boston_scaled[ind,]
km4 <-kmeans(train, centers= 3)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, 
        color=as.factor(km4$cluster), type= 'scatter3d', mode='markers')

 
```
